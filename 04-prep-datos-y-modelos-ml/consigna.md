# Ejercicio 游끼

## 游늸 Objetivo
<br>Realizar la preparaci칩n de datos de la Encuesta anual de hogares realizada en todo el territorio de la Ciudad de Buenos Aires, Argentina en el 2019.
<br>Pr치cticamente vas a acondicionar el dataset para que te quede listo para buscar correlaciones o entrenar alg칰n modelo de Machine Learning.

El dataset proviene del Open Data del Gobierno de Buenos Aires: [Encuesta anual de hogares 2019](https://data.buenosaires.gob.ar/dataset/encuesta-anual-hogares)

---
## 游늸 Consigna 1

**_1) Cargamos los datos_**
- Carguen el dataset:
```
  data = pd.read_csv("encuesta-anual-hogares-2019.csv", sep=',') 
```
**_2) Inspecci칩n inicial_**
- Eliminen las columnas `id` y `hijos_nacidos_vivos`

**_3) Discretizaci칩n_**
- Para las siguientes columnas discreticen por igual frecuencia e igual rango.
    <br>`ingresos_familiares` con q=8
    <br>`ingreso_per_capita_familiar` con q=10

- En algunas situaciones hay ciertos elementos que se repiten al momento de discretizar, una forma de eliminar duplicados es con el argumento `duplicates='drop'`.
    <br><br>Para las siguientes columnas `ingreso_total_lab` y `ingreso_total_no_lab` consideren:
    ```
    data['ingreso_total_lab'] = pd.qcut(data['ingreso_total_lab'], q=10, duplicates='drop')
    data['ingreso_total_no_lab'] = pd.qcut(data['ingreso_total_no_lab'], q=4, duplicates='drop')
    ```

- Para la columna `edad` discreticen usando igual distancia (rango) con `bins=5`.

**_4) Preparaci칩n de datos_**
- Cambien el tipo de dato a `str` de las siguientes columnas: `comuna` y `nhogar`.
  <br>_쯇or qu칠 hacemos esto?_ Para estas columnas el n칰mero es simplemente una connotaci칩n, para representar una comuna por ejemplo pero no hay una relaci칩n num칠rica entre ellos.

- _쯈u칠 esperas como valor en la columna `a침os_escolaridad`?_ N칰mero enteros pero no siempre es as칤, cada entidad o empresa tiene diferentes formas de rellenar una encuesta.
    <br>Evalua lo siguiente: `data['a침os_escolaridad'].unique()`, vas a poder ver los valores 칰nicos en la columna. Donde destacamos que todos son `object/string`.

- Reemplazar `Ningun a침o de escolaridad aprobado` por un '0'. 
<br>Efectivamente por '0' y no 0, porque esta columna maneja datos tipo `object/string`.
    ```
    data['a침os_escolaridad'] = data['a침os_escolaridad'].replace('Ningun a침o de escolaridad aprobado', '0')
    ```

- Vamos a convertir los tipos de datos de la columna anterior `a침os_escolaridad` a enteros.
    <br>De manera intuitiva podr칤amos hacer:
    ```
    data['a침os_escolaridad'] = data['a침os_escolaridad'].astype("Int32")
    ```
    PEROOOOOOO marca un error, 쯖ierto?
    
    Posiblemente muchas veces les pase que cuando hagan una _cast_ (conversi칩n de un tipo de dato a otro) pueden llegar a tener conflictos si esa columna tienen _NaN_. Para este caso si queremos convertir los valores de la columna `a침os_escolaridad` de _string_ a _int_, hay que hacer un paso intermedio que es pasarlo a _float_.
    ```
    data['a침os_escolaridad'] = data['a침os_escolaridad'].astype(float).astype("Int32")
    ```

- Discreticen para la columna `a침os_escolaridad` por igual frecuencia e igual rango con un `q=5`

- No necesariamente siempre hay que rellenar los `NaN` en todas las columnas, porque quiz치s esa cantidad de `NaN` no es tan representativa para nuestro an치lisis. As칤 que podes eliminarlo para todo el dataframe o para ciertas columnas.
    ```
    # Eliminar filas que contengan NaN
    data = data.dropna(subset=['situacion_conyugal', 'sector_educativo', 'lugar_nacimiento', 'afiliacion_salud'])
    ```
- Despu칠s de eliminar filas, podes resetear el 칤ndice para que mantenga la secuencia:
    ```
    data = data.reset_index(drop=True)
    ```

- Rellenar los datos faltantes para la columna `a침os_escolaridad`. Primero a침adan la categor칤a `desconocido` y luego hacen un rellenado de los datos faltantes con `desconocido`.

- Rellenar los datos faltantes para la columna `nivel_max_educativo` con `value=desconocido`

## 游늸 Respuesta esperada 1

Si hacen `status(data)` deber칤an obtener lo siguiente :

---

respuesta_1 = pd.read_csv("tarea_respuesta1.csv", sep=',') 

respuesta_1

## 游늸 Consigna 2

---

**_5) One hot encoding_**

- Hagan `data_ohe = pd.get_dummies(data)`
- Guardar `data_ohe` en un archivo pickle como vimos en clase con el nombre `categories_ohe.pickle`.
- Carguen el dataset `new_data = pd.read_csv("new_data.csv", sep=',')`
- A `new_data` hagan un reindex con las columnas que guardaron el archivo pickle y para los valores `NaN` rellenenlos con un `0`.

## 游늸 Respuesta esperada 2

---

respuesta_2 = pd.read_csv("tarea_respuesta2.csv", sep=',') 

respuesta_2

## 游늸 Consigna 3

Cargar su notebook y datasets a un repositorio p칰blico personal y compartirlo por Discord.
<br>Consideren usar git lfs para los dataset con extensi칩n csv.